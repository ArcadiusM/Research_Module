\subsubsection{Bias Variance Decomposition}
For both simulation setups, we decomposed the 
expected generalization error of the
Random Forest estimator. We included the figures for both 
cases in the appendix (\ref{sec:appendix}). 
Figure \ref{fig:bias_var_linear} illustrates the decomposition of the
linear setup and 
figure \ref{fig:bias_var_nonlinear} that of the non-linear setup. 
In both figures, the expected generalization error 
is denoted as a loss. 
In the linear case, as sample size increases, both 
the expected generalization error and bias tend to decrease, 
yet while being regularly low, the variance of 
Random Forest estimator does not show any pattern. 
Theoretically, we expect low variance and 
the figure is in line with our expectations.
On the other hand, the case with non-linear DGP emphasizes 
more the power of Decision Trees embedded in Random Forest. 
The expected generalization error is driven primarily 
by variance and bias remains low for all sample sizes. 
Since the Decision Tree yields low bias estimates, and 
the variance decreases with sample size, the
figure is consistent with our expectations.
In addition, is a better showcase of Random Forest compared to linear DGP.