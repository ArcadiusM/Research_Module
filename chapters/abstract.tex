\chapter*{Abstract}
As a non-parametric estimation tool, decision trees attract attention in the economics literature. 
Yet, decision trees suffer from high variance and, 
for prediction purposes higher variance seems to be a crucial problem, thus, 
several improvements were proposed such as bootstrap aggregation, boosting and most importantly random forests. 
In this project, while the main focus is being on the random forest.
The elements of statistical learning by \cite{friedman2001elements} \cite{varian2014big} \cite{maimon2005data},
\cite{louppe2014understanding} and as expected \cite{breiman2001random} are the main literature 
that will be utilized in this project.

To explain the concept of random forests in full extent, primarily decision trees should be discussed. 
Exploiting the main idea and struggles with bias-variance trade-off, 
random forests' importance can be emphasized as a more stable prediction tool \cite{maimon2005data}. 
Conceptual comparison of random forests with bagging and boosting can deliver a better understanding of 
its unique features as \cite{lee2019bootstrap} shows in a similar fashion. To get a further understanding, 
random forestsâ€™ estimation process can be mathematical explained \cite{biau2012analysis} and likewise, 
examining the consistency of estimator and showing the properties can be included \cite{breiman2004consistency}, 
\cite{denil2014narrowing}. Also, variable importance in the tree growing process is another area that needs to be 
delved into \cite{ishwaran2007variable} and \cite{louppe2013understanding}.
